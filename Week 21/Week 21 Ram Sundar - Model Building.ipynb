{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd82d917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Data Cleaning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      "id                            int64\n",
      "Gender                       object\n",
      "Age                           int64\n",
      "Travel Category              object\n",
      "Travel Class                 object\n",
      "Distance Travelled            int64\n",
      "Departure/Arrival Rating    float64\n",
      "Booking Ease                float64\n",
      "Boarding Point              float64\n",
      "Food                        float64\n",
      "Seat Comfort                float64\n",
      "Entertainment               float64\n",
      "Leg Room                    float64\n",
      "Luggage Handling            float64\n",
      "Cleanliness                   int64\n",
      "Departure Delay (min)         int64\n",
      "Arrival Delay (min)         float64\n",
      "Satisfaction                 object\n",
      "dtype: object\n",
      "Missing values before cleaning:\n",
      "id                              0\n",
      "Gender                          0\n",
      "Age                             0\n",
      "Travel Category                 0\n",
      "Travel Class                 6283\n",
      "Distance Travelled              0\n",
      "Departure/Arrival Rating    12170\n",
      "Booking Ease                12149\n",
      "Boarding Point               9209\n",
      "Food                        13958\n",
      "Seat Comfort                10136\n",
      "Entertainment                8231\n",
      "Leg Room                    15272\n",
      "Luggage Handling             8253\n",
      "Cleanliness                     0\n",
      "Departure Delay (min)           0\n",
      "Arrival Delay (min)           310\n",
      "Satisfaction                    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Handle missing values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "id                          0\n",
      "Gender                      0\n",
      "Age                         0\n",
      "Travel Category             0\n",
      "Travel Class                0\n",
      "Distance Travelled          0\n",
      "Departure/Arrival Rating    0\n",
      "Booking Ease                0\n",
      "Boarding Point              0\n",
      "Food                        0\n",
      "Seat Comfort                0\n",
      "Entertainment               0\n",
      "Leg Room                    0\n",
      "Luggage Handling            0\n",
      "Cleanliness                 0\n",
      "Departure Delay (min)       0\n",
      "Arrival Delay (min)         0\n",
      "Satisfaction                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Outlier Detection and Removal"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape before outlier removal: (103904, 18)\n",
      "\n",
      "\n",
      "Outlier Analysis:\n",
      "id: 0 outliers (0.00%) -> No outliers detected\n",
      "Age: 0 outliers (0.00%) -> No outliers detected\n",
      "Distance Travelled: 3650 outliers (3.51%) -> Will remove outliers (< 5%)\n",
      "Departure/Arrival Rating: 0 outliers (0.00%) -> No outliers detected\n",
      "Booking Ease: 0 outliers (0.00%) -> No outliers detected\n",
      "Boarding Point: 0 outliers (0.00%) -> No outliers detected\n",
      "Food: 0 outliers (0.00%) -> No outliers detected\n",
      "Seat Comfort: 10892 outliers (10.48%) -> Will keep outliers (>= 5%)\n",
      "Entertainment: 0 outliers (0.00%) -> No outliers detected\n",
      "Leg Room: 9268 outliers (8.92%) -> Will keep outliers (>= 5%)\n",
      "Luggage Handling: 6670 outliers (6.42%) -> Will keep outliers (>= 5%)\n",
      "Cleanliness: 0 outliers (0.00%) -> No outliers detected\n",
      "Departure Delay (min): 14529 outliers (13.98%) -> Will keep outliers (>= 5%)\n",
      "Arrival Delay (min): 13954 outliers (13.43%) -> Will keep outliers (>= 5%)\n",
      "\n",
      "Columns where outliers will be removed: ['Distance Travelled']\n",
      "\n",
      "Removing 3650 rows containing outliers...\n",
      "Dataset shape after outlier removal: (100254, 18)\n",
      "Removed 3650 rows (3.51% of original data)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Data Preparation and Feature Engineering"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature set shape: (100254, 19)\n",
      "Final target variable shape: (100254,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: Satisfaction, dtype: uint8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Exploratory Data Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Correlation of features with target variable Satisfaction:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satisfaction                       1.000000\n",
      "Entertainment                      0.369536\n",
      "Seat Comfort                       0.321039\n",
      "Cleanliness                        0.298401\n",
      "Leg Room                           0.274403\n",
      "Distance Travelled                 0.228934\n",
      "Luggage Handling                   0.226913\n",
      "Food                               0.192798\n",
      "Booking Ease                       0.166159\n",
      "Age                                0.132568\n",
      "Gender_Male                        0.013091\n",
      "id                                 0.010742\n",
      "Boarding Point                    -0.001299\n",
      "Departure/Arrival Rating          -0.046919\n",
      "Departure Delay (min)             -0.050481\n",
      "Total Delay                       -0.054425\n",
      "Arrival Delay (min)               -0.057236\n",
      "Travel Class_Premium              -0.097057\n",
      "Travel Class_Economy              -0.420401\n",
      "Travel Category_Personal Travel   -0.445161\n",
      "Name: Satisfaction, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Model Training & Model Evaluation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (80203, 19), (80203,)\n",
      "Testing set shape: (20051, 19), (20051,)\n",
      "Obtained eval results for 5 models.\n",
      "Obtained eval results for 5 models.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Model Comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.8795\n",
      "Precision (macro avg): 0.8803\n",
      "Recall (macro avg): 0.8715\n",
      "F1-score (macro avg): 0.8750\n",
      "Confusion Matrix:\n",
      "[[10702   907]\n",
      " [ 1510  6932]]\n",
      "\n",
      "~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.8855\n",
      "Precision (macro avg): 0.8847\n",
      "Recall (macro avg): 0.8797\n",
      "F1-score (macro avg): 0.8819\n",
      "Confusion Matrix:\n",
      "[[10640   969]\n",
      " [ 1326  7116]]\n",
      "\n",
      "~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~\n",
      "\n",
      "\n",
      "KNN:\n",
      "Accuracy: 0.8316\n",
      "Precision (macro avg): 0.8285\n",
      "Recall (macro avg): 0.8246\n",
      "F1-score (macro avg): 0.8263\n",
      "Confusion Matrix:\n",
      "[[10088  1521]\n",
      " [ 1856  6586]]\n",
      "\n",
      "~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.9019\n",
      "Precision (macro avg): 0.9009\n",
      "Recall (macro avg): 0.8973\n",
      "F1-score (macro avg): 0.8990\n",
      "Confusion Matrix:\n",
      "[[10752   857]\n",
      " [ 1110  7332]]\n",
      "\n",
      "~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.8214\n",
      "Precision (macro avg): 0.8171\n",
      "Recall (macro avg): 0.8160\n",
      "F1-score (macro avg): 0.8165\n",
      "Confusion Matrix:\n",
      "[[9871 1738]\n",
      " [1843 6599]]\n",
      "\n",
      "~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~~.~\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Best Model Selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best Model: XGBoost\n",
      "üéñÔ∏è Best Accuracy: 0.9019\n",
      "\n",
      "\n",
      "üèÜ Best Model by F1-score: XGBoost\n",
      "üéñÔ∏è Best F1-score: 0.8990\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Model Comparison Table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.8819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>0.8803</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.8263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.8171</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.8165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision  Recall  F1-Score\n",
       "3              XGBoost    0.9019     0.9009  0.8973    0.8990\n",
       "1        Random Forest    0.8855     0.8847  0.8797    0.8819\n",
       "0        Decision Tree    0.8795     0.8803  0.8715    0.8750\n",
       "2                  KNN    0.8316     0.8285  0.8246    0.8263\n",
       "4  Logistic Regression    0.8214     0.8171  0.8160    0.8165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "cust_df = pd.read_csv(\"Customer Satisfaction.csv\")\n",
    "\n",
    "\"\"\"\n",
    "The goal of this project is to analyse the factors influencing customer satisfaction in road transport. \n",
    "By examining the relationships between various attributes such as age, travel category, distance travelled, and service ratings, \n",
    "we aim to build a predictive model that identifies the key drivers of a 'Satisfied' or 'Neutral or Dissatisfied' outcome.\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(\"# Data Cleaning\"))\n",
    "\n",
    "# Print data types of each column in the df\n",
    "print(\"Data types of each column:\")\n",
    "print(cust_df.dtypes)\n",
    "\n",
    "\n",
    "# Check missing values before cleaning\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(cust_df.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"## Handle missing values\"))\n",
    "# Handle missing values appropriately\n",
    "# This will come in handy later during scaling where we could specify what columns to scale\n",
    "# For numeric columns: use median\n",
    "\n",
    "numeric_cols = cust_df.select_dtypes(include=[np.number]).columns\n",
    "cust_df[numeric_cols] = cust_df[numeric_cols].fillna(cust_df[numeric_cols].median())\n",
    "\n",
    "# For categorical columns: use mode\n",
    "categorical_cols = cust_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if cust_df[col].isnull().sum() > 0:\n",
    "        mode_value = cust_df[col].mode()[0] if not cust_df[col].mode().empty else 'Unknown'\n",
    "        cust_df[col] = cust_df[col].fillna(mode_value)\n",
    "\n",
    "# Verify missing values after cleaning\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(cust_df.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Handle Outliers- Remove them if % of outliers in a column is less than 5% else leave it.\n",
    "display(Markdown(\"## Outlier Detection and Removal\"))\n",
    "\n",
    "print(f\"Dataset shape before outlier removal: {cust_df.shape}\")\n",
    "print(\"\\n\")\n",
    "print(\"Outlier Analysis:\")\n",
    "\n",
    "def get_outliers(df, column):\n",
    "    \"\"\"Detect outliers using IQR method. Use industry standard 1.5*IQR rule.\"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR    \n",
    "    outlier_rows = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outlier_rows.index\n",
    "\n",
    "# Store original dataset size\n",
    "original_size = len(cust_df)\n",
    "\n",
    "# Check outliers for each numeric column\n",
    "columns_to_clean = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    outlier_indices = get_outliers(cust_df, col)\n",
    "    outlier_percentage = (len(outlier_indices) / original_size) * 100    \n",
    "    print(f\"{col}: {len(outlier_indices)} outliers ({outlier_percentage:.2f}%)\", end=\"\")    \n",
    "    if outlier_percentage == 0.0:\n",
    "        print(\" -> No outliers detected\")\n",
    "        continue\n",
    "    elif outlier_percentage < 5.0:\n",
    "        columns_to_clean.append(col)\n",
    "        print(\" -> Will remove outliers (< 5%)\")\n",
    "    else:\n",
    "        print(\" -> Will keep outliers (>= 5%)\")\n",
    "\n",
    "print(f\"\\nColumns where outliers will be removed: {columns_to_clean}\")\n",
    "\n",
    "# Remove outliers from columns where they represent < 5% of data\n",
    "outliers_to_remove = set()\n",
    "for col in columns_to_clean:\n",
    "    outlier_indices = get_outliers(cust_df, col)\n",
    "    outliers_to_remove.update(outlier_indices)\n",
    "\n",
    "if outliers_to_remove:\n",
    "    print(f\"\\nRemoving {len(outliers_to_remove)} rows containing outliers...\")\n",
    "    cust_df = cust_df.drop(outliers_to_remove).reset_index(drop=True)\n",
    "    print(f\"Dataset shape after outlier removal: {cust_df.shape}\")\n",
    "    print(f\"Removed {original_size - len(cust_df)} rows ({((original_size - len(cust_df)) / original_size) * 100:.2f}% of original data)\")\n",
    "else:\n",
    "    print(\"\\nNo outliers removed (all columns had >= 5% outliers)\")\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"# Data Preparation and Feature Engineering\"))\n",
    "# Encode categorical variables using one-hot encoding. We already have categorical_cols from before\n",
    "cust_df = pd.get_dummies(cust_df, columns=categorical_cols, drop_first=True, dtype=np.uint8)\n",
    "\n",
    "# Create a new column TotalDelay as the sum of all delay columns - Departure Delay (min) and Arrival Delay (min)\n",
    "cust_df[\"Total Delay\"] = cust_df[\"Departure Delay (min)\"] + cust_df[\"Arrival Delay (min)\"]\n",
    "\n",
    "# Scale numeric features from numeric_cols using Min-Max Scaling to bring them to a 0-1 range\n",
    "scaler = MinMaxScaler()\n",
    "cust_df[numeric_cols] = scaler.fit_transform(cust_df[numeric_cols])\n",
    "\n",
    "# Rename column Satisfaction_satisfied to Satisfaction\n",
    "cust_df.rename(columns={\"Satisfaction_satisfied\": \"Satisfaction\"}, inplace=True)\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = cust_df.drop(\"Satisfaction\", axis=1)\n",
    "y = cust_df[\"Satisfaction\"]\n",
    "\n",
    "# Display X and y shapes\n",
    "print(f\"Final feature set shape: {X.shape}\")\n",
    "print(f\"Final target variable shape: {y.shape}\")\n",
    "display(y.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"# Exploratory Data Analysis\"))\n",
    "# In cust_df find out how all other variables are correlated to the target variable Satisfaction\n",
    "# Display correlation of all features with target variable Satisfaction\n",
    "correlations = cust_df.corr()[\"Satisfaction\"].sort_values(ascending=False)\n",
    "display(Markdown(\"## Correlation of features with target variable Satisfaction:\"))\n",
    "print(correlations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"# Model Training & Model Evaluation\"))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Note - stratify=y to maintain class distribution in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28, stratify=y)\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Define all models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=20, min_samples_leaf=10, random_state=28)\n",
    "    , \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=20, random_state=28)\n",
    "    , \"KNN\": KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
    "    , \"XGBoost\": XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=28)    \n",
    "    , \"Logistic Regression\": LogisticRegression(random_state=28, max_iter=1000)    \n",
    "}\n",
    "\n",
    "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):        \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": class_report,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"predictions\": y_pred\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "all_results = []\n",
    "for model_name, model in models.items():        \n",
    "    all_results.append(evaluate_model(model, model_name, X_train, X_test, y_train, y_test))\n",
    "\n",
    "print(f\"Obtained eval results for {len(all_results)} models.\")\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"## Model Comparison\"))\n",
    "\n",
    "for result in all_results:\n",
    "    print(\"\\n\")\n",
    "    print(f\"{result[\"model_name\"]}:\")\n",
    "    print(f\"Accuracy: {result[\"accuracy\"]:.4f}\")\n",
    "    print(f\"Precision (macro avg): {result[\"classification_report\"][\"macro avg\"][\"precision\"]:.4f}\")\n",
    "    print(f\"Recall (macro avg): {result[\"classification_report\"][\"macro avg\"][\"recall\"]:.4f}\")\n",
    "    print(f\"F1-score (macro avg): {result[\"classification_report\"][\"macro avg\"][\"f1-score\"]:.4f}\")\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(f\"{result[\"confusion_matrix\"]}\")\n",
    "    print(\"\\n\" + \"~.~\"*50)\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"## Best Model Selection\"))\n",
    "\n",
    "# Best model based on accuracy\n",
    "best_model = max(all_results, key=lambda x: x[\"accuracy\"])\n",
    "print(f\"üèÜ Best Model: {best_model[\"model_name\"]}\")\n",
    "print(f\"üéñÔ∏è Best Accuracy: {best_model[\"accuracy\"]:.4f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Best model based on F1-score\n",
    "best_model_f1 = max(all_results, key=lambda x: x[\"classification_report\"][\"macro avg\"][\"f1-score\"])\n",
    "print(f\"üèÜ Best Model by F1-score: {best_model_f1[\"model_name\"]}\")\n",
    "print(f\"üéñÔ∏è Best F1-score: {best_model_f1[\"classification_report\"][\"macro avg\"][\"f1-score\"]:.4f}\")\n",
    "\n",
    "# Create a comparison table\n",
    "comparison_data = []\n",
    "for result in all_results:\n",
    "    comparison_data.append(\n",
    "        {\n",
    "        \"Model\": result[\"model_name\"],\n",
    "        \"Accuracy\": result[\"accuracy\"],\n",
    "        \"Precision\": result[\"classification_report\"][\"macro avg\"][\"precision\"],\n",
    "        \"Recall\": result[\"classification_report\"][\"macro avg\"][\"recall\"],\n",
    "        \"F1-Score\": result[\"classification_report\"][\"macro avg\"][\"f1-score\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "display(Markdown(\"## Model Comparison Table\"))\n",
    "display(comparison_df.round(4))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
