{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e0181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.9.4)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (2.20.0)\n",
      "Requirement already satisfied: keras in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.60.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 4)) (6.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (58.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (2.20.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 9)) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 9)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 9)) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 9)) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 9)) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.9/site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.9/site-packages (from keras->-r requirements.txt (line 10)) (14.2.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.9/site-packages (from keras->-r requirements.txt (line 10)) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.9/site-packages (from keras->-r requirements.txt (line 10)) (0.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 9)) (0.45.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 4)) (3.23.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./.venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 9)) (8.7.1)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.9/site-packages (from rich->keras->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from rich->keras->-r requirements.txt (line 10)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras->-r requirements.txt (line 10)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in ./.venv/lib/python3.9/site-packages (25.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (58.0.4)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in ./.venv/lib/python3.9/site-packages (0.45.1)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 58.0.4\n",
      "    Uninstalling setuptools-58.0.4:\n",
      "      Successfully uninstalled setuptools-58.0.4\n",
      "Successfully installed setuptools-80.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spacy[apple]\n",
      "  Using cached spacy-3.8.11-cp39-cp39-macosx_10_9_universal2.whl\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy[apple])\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy[apple])\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy[apple])\n",
      "  Using cached murmurhash-1.0.15-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy[apple])\n",
      "  Using cached cymem-2.0.13-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy[apple])\n",
      "  Using cached preshed-3.0.12-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy[apple])\n",
      "  Using cached thinc-8.3.9-cp39-cp39-macosx_10_9_universal2.whl\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy[apple])\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy[apple])\n",
      "  Using cached srsly-2.5.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy[apple])\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy[apple])\n",
      "  Using cached weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy[apple])\n",
      "  Using cached typer_slim-0.20.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.9/site-packages (from spacy[apple]) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from spacy[apple]) (2.32.5)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy[apple])\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting jinja2 (from spacy[apple])\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (from spacy[apple]) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from spacy[apple]) (25.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.9/site-packages (from spacy[apple]) (2.0.2)\n",
      "Collecting thinc-apple-ops<2.0.0,>=1.0.0 (from spacy[apple])\n",
      "  Using cached thinc_apple_ops-1.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[apple])\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[apple])\n",
      "  Using cached pydantic_core-2.41.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./.venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[apple]) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[apple])\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (2025.11.12)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy[apple])\n",
      "  Using cached blis-1.3.3-cp39-cp39-macosx_10_9_universal2.whl\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy[apple])\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim<1.0.0,>=0.3.0->spacy[apple])\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy[apple])\n",
      "  Using cached cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy[apple])\n",
      "  Using cached smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy[apple]) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->spacy[apple]) (3.0.3)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.13-cp39-cp39-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached murmurhash-1.0.15-cp39-cp39-macosx_11_0_arm64.whl (27 kB)\n",
      "Using cached preshed-3.0.12-cp39-cp39-macosx_11_0_arm64.whl (126 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.2-cp39-cp39-macosx_11_0_arm64.whl (654 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached thinc_apple_ops-1.0.0-cp39-cp39-macosx_11_0_arm64.whl (157 kB)\n",
      "Using cached typer_slim-0.20.1-py3-none-any.whl (47 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Using cached smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Installing collected packages: wasabi, typing-inspection, spacy-loggers, spacy-legacy, smart-open, pydantic-core, murmurhash, jinja2, cymem, cloudpathlib, click, catalogue, blis, annotated-types, typer-slim, srsly, pydantic, preshed, confection, weasel, thinc, thinc-apple-ops, spacy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [spacy]m22/23\u001b[0m [spacy]ic]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 blis-1.3.3 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 jinja2-3.1.6 murmurhash-1.0.15 preshed-3.0.12 pydantic-2.12.5 pydantic-core-2.41.5 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.9 thinc-apple-ops-1.0.0 typer-slim-0.20.1 typing-inspection-0.4.2 wasabi-1.1.3 weasel-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/ramsundar/Documents/IITM-Graded-Projects/Week 31/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%pip install -r requirements.txt\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U \"spacy[apple]\"\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbce8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53895c",
   "metadata": {},
   "source": [
    "# Part 1 - Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe75f8",
   "metadata": {},
   "source": [
    "## 1.1 Loading the dataset & 1.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212e1f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69490/69490 [00:47<00:00, 1476.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_setup_data() -> pd.DataFrame:\n",
    "    df = pd.read_csv(\"twitter_training.csv\")    \n",
    "    # First column appers to be some sort file or sequence number and the second appears to be the source\n",
    "    # Those two columns do not have any impact on sentiment analysis\n",
    "    # Take the last two columns\n",
    "    df = df.iloc[:, -2:]\n",
    "    # Swap columns 1 and 2\n",
    "    df = df[[df.columns[1], df.columns[0]]]\n",
    "    # Setup column names\n",
    "    df.columns = [\"tweet\", \"sentiment\"]\n",
    "    # Remove empty rows\n",
    "    df = df.dropna()\n",
    "    # Remove diuplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "    # Look for tweets where the same tweet is classified as a different sentiment\n",
    "    # Take the first occurence - this will get us clean data and will not mislead the classifier later during training\n",
    "    df = df.drop_duplicates(subset=[\"tweet\"], keep=\"first\")\n",
    "    return df\n",
    "\n",
    "df = load_and_setup_data()\n",
    "\n",
    "\n",
    "# Just keep the essentials, remove named entities, parsing and sentence segmentation for speed\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"senter\"])\n",
    "\n",
    "\n",
    "def clean_and_pre_process(text: str) -> str:    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    # Remove user @ references and '#' from hashtags\n",
    "    text = re.sub(r\"\\@\\w+|\\#\", \"\", text)\n",
    "    # Remove special characters and numbers (keep only letters)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()    \n",
    "    # Tokenization, Stop Word Removal, and Lemmatization via spaCy\n",
    "    doc = nlp(text)    \n",
    "    # Filter out stop words and punctuation, then take the lemma\n",
    "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]    \n",
    "    # Join back into a string \n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "df[\"sanitized_tweet\"] = df[\"tweet\"].progress_apply(clean_and_pre_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ab132",
   "metadata": {},
   "source": [
    "## 1.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e24408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sanitized_tweet</th>\n",
       "      <th>tfidf_vector</th>\n",
       "      <th>sanitized_tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>come border kill</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>m get borderland kill</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>m come borderland murder</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>m get borderland   murder</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>m get borderland murder</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0  I am coming to the borders and I will kill you...  Positive   \n",
       "1  im getting on borderlands and i will kill you ...  Positive   \n",
       "2  im coming on borderlands and i will murder you...  Positive   \n",
       "3  im getting on borderlands 2 and i will murder ...  Positive   \n",
       "4  im getting into borderlands and i can murder y...  Positive   \n",
       "\n",
       "             sanitized_tweet  \\\n",
       "0           come border kill   \n",
       "1      m get borderland kill   \n",
       "2   m come borderland murder   \n",
       "3  m get borderland   murder   \n",
       "4    m get borderland murder   \n",
       "\n",
       "                                        tfidf_vector  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 0.0,...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...   \n",
       "\n",
       "                              sanitized_tweet_vector  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 0.0,...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 2.6871612, 0.0, 2.91...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tokenized_words(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    texts = df[\"sanitized_tweet\"].values\n",
    "    # TF-IDF vectorizer\n",
    "    tfidf_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=10000,\n",
    "        output_mode=\"tf_idf\"\n",
    "    )\n",
    "    tfidf_vectorizer.adapt(texts)\n",
    "    # Convert text to TF-IDF vectors\n",
    "    tfidf_vectors = tfidf_vectorizer(texts)\n",
    "    # add the tokenized words as a new column\n",
    "    df[\"sanitized_tweet_vector\"] = list(tfidf_vectors.numpy())\n",
    "    return df\n",
    "\n",
    "df = create_tokenized_words(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da02229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
